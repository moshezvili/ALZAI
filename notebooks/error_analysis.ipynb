{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6689826",
   "metadata": {},
   "source": [
    "# Clinical ML Model - Error Analysis\n",
    "\n",
    "This notebook provides comprehensive error analysis for the clinical ML binary classification model, including:\n",
    "\n",
    "1. **Slice Analysis**: Performance across demographic subgroups\n",
    "2. **Feature Analysis**: Important features and their stability\n",
    "3. **Temporal Analysis**: Performance over different time periods\n",
    "4. **Error Pattern Analysis**: Common misclassification patterns\n",
    "5. **Calibration Assessment**: Model probability calibration\n",
    "6. **Improvement Recommendations**: Concrete suggestions for enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebdf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_curve, precision_recall_curve,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaf94a",
   "metadata": {},
   "source": [
    "## 1. Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c8aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'imblearn.pipeline.Pipeline'>\n",
      "Optimal threshold: 0.500\n",
      "Feature names not found\n"
     ]
    }
   ],
   "source": [
    "# Add src to Python path for model loading\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load the trained model\n",
    "model_path = '../models/best_model.joblib'\n",
    "model = joblib.load(model_path)\n",
    "print(f\"Model loaded: {type(model)}\")\n",
    "\n",
    "# Load optimal threshold\n",
    "threshold_path = '../models/optimal_threshold.txt'\n",
    "with open(threshold_path, 'r') as f:\n",
    "    optimal_threshold = float(f.read().strip())\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "# Load feature names\n",
    "features_path = '../models/feature_names.txt'\n",
    "if Path(features_path).exists():\n",
    "    with open(features_path, 'r') as f:\n",
    "        feature_names = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Feature names loaded: {len(feature_names)} features\")\n",
    "else:\n",
    "    feature_names = None\n",
    "    print(\"Feature names not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb8df4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1537514, 29)\n",
      "Target distribution: target\n",
      "0    0.93\n",
      "1    0.07\n",
      "Name: proportion, dtype: float64\n",
      "Generating predictions...\n",
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.pipeline.feature_engineering:Creating temporal rolling features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating predictions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m y_pred_proba = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     15\u001b[39m y_pred = (y_pred_proba >= optimal_threshold).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredictions generated for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\imblearn\\pipeline.py:852\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    851\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict_proba(Xt, **params)\n\u001b[32m    855\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\notebooks\\..\\src\\pipeline\\feature_engineering.py:114\u001b[39m, in \u001b[36mTemporalFeatureEngineer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    109\u001b[39m         x = np.arange(\u001b[38;5;28mlen\u001b[39m(series))\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.polyfit(x, series, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m series.isna().all() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    112\u001b[39m     rolling_result = \u001b[43mgrouped\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwindow_years\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_trend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     X_sorted[new_col] = rolling_result.values\n\u001b[32m    117\u001b[39m new_features.append(new_col)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:2049\u001b[39m, in \u001b[36mRolling.apply\u001b[39m\u001b[34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[39m\n\u001b[32m   2016\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   2017\u001b[39m     template_header,\n\u001b[32m   2018\u001b[39m     create_section_header(\u001b[33m\"\u001b[39m\u001b[33mParameters\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2047\u001b[39m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2048\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2056\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1508\u001b[39m, in \u001b[36mRollingAndExpandingMixin.apply\u001b[39m\u001b[34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[39m\n\u001b[32m   1505\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1506\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mengine must be either \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumba\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcython\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapply\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:723\u001b[39m, in \u001b[36mBaseWindowGroupby._apply\u001b[39m\u001b[34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply\u001b[39m(\n\u001b[32m    716\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    717\u001b[39m     func: Callable[..., Any],\n\u001b[32m   (...)\u001b[39m\u001b[32m    721\u001b[39m     **kwargs,\n\u001b[32m    722\u001b[39m ) -> DataFrame | Series:\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# Reconstruct the resulting MultiIndex\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# 1st set of levels = group by labels\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# 2nd set of levels = original DataFrame/Series index\u001b[39;00m\n\u001b[32m    733\u001b[39m     grouped_object_index = \u001b[38;5;28mself\u001b[39m.obj.index\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:619\u001b[39m, in \u001b[36mBaseWindow._apply\u001b[39m\u001b[34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[39m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method == \u001b[33m\"\u001b[39m\u001b[33msingle\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_columnwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:472\u001b[39m, in \u001b[36mBaseWindow._apply_columnwise\u001b[39m\u001b[34m(self, homogeneous_func, name, numeric_only)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_numeric_only(name, numeric_only)\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._create_data(\u001b[38;5;28mself\u001b[39m._selected_obj, numeric_only)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:456\u001b[39m, in \u001b[36mBaseWindow._apply_series\u001b[39m\u001b[34m(self, homogeneous_func, name)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[33m\"\u001b[39m\u001b[33mNo numeric types to aggregate\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m result = \u001b[43mhomogeneous_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m index = \u001b[38;5;28mself\u001b[39m._slice_axis_for_step(obj.index, result)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor(result, index=index, name=obj.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:614\u001b[39m, in \u001b[36mBaseWindow._apply.<locals>.homogeneous_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, *numba_args)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     result = \u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:611\u001b[39m, in \u001b[36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    602\u001b[39m start, end = window_indexer.get_window_bounds(\n\u001b[32m    603\u001b[39m     num_values=\u001b[38;5;28mlen\u001b[39m(x),\n\u001b[32m    604\u001b[39m     min_periods=min_periods,\n\u001b[32m   (...)\u001b[39m\u001b[32m    607\u001b[39m     step=\u001b[38;5;28mself\u001b[39m.step,\n\u001b[32m    608\u001b[39m )\n\u001b[32m    609\u001b[39m \u001b[38;5;28mself\u001b[39m._check_window_bounds(start, end, \u001b[38;5;28mlen\u001b[39m(x))\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1535\u001b[39m, in \u001b[36mRollingAndExpandingMixin._generate_cython_apply_func.<locals>.apply_func\u001b[39m\u001b[34m(values, begin, end, min_periods, raw)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[32m   1533\u001b[39m     \u001b[38;5;66;03m# GH 45912\u001b[39;00m\n\u001b[32m   1534\u001b[39m     values = Series(values, index=\u001b[38;5;28mself\u001b[39m._on, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwindow_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/window/aggregations.pyx:1422\u001b[39m, in \u001b[36mpandas._libs.window.aggregations.roll_apply\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\dev\\ALZAI\\notebooks\\..\\src\\pipeline\\feature_engineering.py:109\u001b[39m, in \u001b[36mTemporalFeatureEngineer.transform.<locals>.calculate_trend\u001b[39m\u001b[34m(series)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(series) < \u001b[32m2\u001b[39m:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m x = np.arange(\u001b[38;5;28mlen\u001b[39m(series))\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.polyfit(x, series, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m series.isna().all() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load test data (or use full dataset for analysis)\n",
    "data_path = '../data/raw/clinical_data.parquet'\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Target distribution: {df['target'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Separate features and target\n",
    "y_true = df['target']\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "# Make predictions\n",
    "print(\"Generating predictions...\")\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(f\"Predictions generated for {len(y_true)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c91bb7",
   "metadata": {},
   "source": [
    "## 2. Overall Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score(y_true, y_pred),\n",
    "    'Precision': precision_score(y_true, y_pred),\n",
    "    'Recall': recall_score(y_true, y_pred),\n",
    "    'F1-Score': f1_score(y_true, y_pred),\n",
    "    'ROC-AUC': roc_auc_score(y_true, y_pred_proba),\n",
    "    'PR-AUC': average_precision_score(y_true, y_pred_proba)\n",
    "}\n",
    "\n",
    "# Display metrics\n",
    "metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n",
    "print(\"Overall Model Performance:\")\n",
    "print(metrics_df.round(4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix Breakdown:\")\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives: {tn:,}\")\n",
    "print(f\"False Positives: {fp:,}\")\n",
    "print(f\"False Negatives: {fn:,}\")\n",
    "print(f\"True Positives: {tp:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106686d",
   "metadata": {},
   "source": [
    "## 3. Slice Analysis Across Demographic Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5bad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slice_metrics(y_true, y_pred, y_proba, slice_mask, slice_name):\n",
    "    \"\"\"Calculate metrics for a specific slice.\"\"\"\n",
    "    if slice_mask.sum() < 10:  # Skip slices with too few samples\n",
    "        return None\n",
    "    \n",
    "    metrics = {\n",
    "        'Slice': slice_name,\n",
    "        'Sample_Size': slice_mask.sum(),\n",
    "        'Positive_Rate': y_true[slice_mask].mean(),\n",
    "        'Accuracy': accuracy_score(y_true[slice_mask], y_pred[slice_mask]),\n",
    "        'Precision': precision_score(y_true[slice_mask], y_pred[slice_mask], zero_division=0),\n",
    "        'Recall': recall_score(y_true[slice_mask], y_pred[slice_mask], zero_division=0),\n",
    "        'F1_Score': f1_score(y_true[slice_mask], y_pred[slice_mask], zero_division=0),\n",
    "        'ROC_AUC': roc_auc_score(y_true[slice_mask], y_proba[slice_mask]) if len(np.unique(y_true[slice_mask])) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Analyze performance by gender\n",
    "print(\"=== Performance by Gender ===\")\n",
    "gender_results = []\n",
    "for gender in df['gender'].unique():\n",
    "    mask = df['gender'] == gender\n",
    "    metrics = calculate_slice_metrics(y_true, y_pred, y_pred_proba, mask, f\"Gender_{gender}\")\n",
    "    if metrics:\n",
    "        gender_results.append(metrics)\n",
    "\n",
    "gender_df = pd.DataFrame(gender_results)\n",
    "print(gender_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d44352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance by age group\n",
    "print(\"\\n=== Performance by Age Group ===\")\n",
    "age_results = []\n",
    "for age_group in df['age_group'].unique():\n",
    "    if pd.isna(age_group):\n",
    "        continue\n",
    "    mask = df['age_group'] == age_group\n",
    "    metrics = calculate_slice_metrics(y_true, y_pred, y_pred_proba, mask, f\"Age_{age_group}\")\n",
    "    if metrics:\n",
    "        age_results.append(metrics)\n",
    "\n",
    "age_df = pd.DataFrame(age_results)\n",
    "print(age_df.round(3))\n",
    "\n",
    "# Visualize age group performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=age_df, x='Slice', y='ROC_AUC')\n",
    "plt.title('ROC-AUC by Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(data=age_df, x='Slice', y='F1_Score')\n",
    "plt.title('F1-Score by Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance by smoking status\n",
    "print(\"\\n=== Performance by Smoking Status ===\")\n",
    "smoking_results = []\n",
    "for smoking_status in df['smoking_status'].unique():\n",
    "    mask = df['smoking_status'] == smoking_status\n",
    "    metrics = calculate_slice_metrics(y_true, y_pred, y_pred_proba, mask, f\"Smoking_{smoking_status}\")\n",
    "    if metrics:\n",
    "        smoking_results.append(metrics)\n",
    "\n",
    "smoking_df = pd.DataFrame(smoking_results)\n",
    "print(smoking_df.round(3))\n",
    "\n",
    "# Analyze performance by primary diagnosis\n",
    "print(\"\\n=== Performance by Top Primary Diagnoses ===\")\n",
    "top_diagnoses = df['primary_diagnosis'].value_counts().head(5).index\n",
    "diagnosis_results = []\n",
    "\n",
    "for diagnosis in top_diagnoses:\n",
    "    mask = df['primary_diagnosis'] == diagnosis\n",
    "    metrics = calculate_slice_metrics(y_true, y_pred, y_pred_proba, mask, f\"Diagnosis_{diagnosis}\")\n",
    "    if metrics:\n",
    "        diagnosis_results.append(metrics)\n",
    "\n",
    "diagnosis_df = pd.DataFrame(diagnosis_results)\n",
    "print(diagnosis_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a06e4",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea76e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from the model\n",
    "if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "    feature_importance = model.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Get transformed feature names\n",
    "    X_transformed = model.named_steps['preprocessing'].transform(X.iloc[:100])  # Sample for speed\n",
    "    if hasattr(X_transformed, 'columns'):\n",
    "        transformed_feature_names = X_transformed.columns.tolist()\n",
    "    else:\n",
    "        transformed_feature_names = [f'feature_{i}' for i in range(X_transformed.shape[1])]\n",
    "    \n",
    "    # Create importance dataframe\n",
    "    if len(transformed_feature_names) == len(feature_importance):\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': transformed_feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot top 20 features\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(20)\n",
    "        sns.barplot(data=top_features, y='feature', x='importance')\n",
    "        plt.title('Top 20 Most Important Features')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Top 10 Most Important Features:\")\n",
    "        print(importance_df.head(10))\n",
    "    else:\n",
    "        print(f\"Feature count mismatch: {len(transformed_feature_names)} vs {len(feature_importance)}\")\n",
    "else:\n",
    "    print(\"Feature importance not available for this model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d3846",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance by year\n",
    "print(\"=== Performance by Year ===\")\n",
    "yearly_results = []\n",
    "for year in sorted(df['year'].unique()):\n",
    "    mask = df['year'] == year\n",
    "    metrics = calculate_slice_metrics(y_true, y_pred, y_pred_proba, mask, f\"Year_{year}\")\n",
    "    if metrics:\n",
    "        yearly_results.append(metrics)\n",
    "\n",
    "yearly_df = pd.DataFrame(yearly_results)\n",
    "print(yearly_df.round(3))\n",
    "\n",
    "# Plot temporal trends\n",
    "if len(yearly_df) > 1:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(yearly_df['Slice'].str.replace('Year_', '').astype(int), yearly_df['ROC_AUC'], marker='o')\n",
    "    plt.title('ROC-AUC Over Time')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(yearly_df['Slice'].str.replace('Year_', '').astype(int), yearly_df['Positive_Rate'], marker='o', color='orange')\n",
    "    plt.title('Positive Rate Over Time')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Positive Rate')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(yearly_df['Slice'].str.replace('Year_', '').astype(int), yearly_df['Sample_Size'], marker='o', color='green')\n",
    "    plt.title('Sample Size Over Time')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Sample Size')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c52533",
   "metadata": {},
   "source": [
    "## 6. Error Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fec9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze false positives and false negatives\n",
    "false_positives = (y_true == 0) & (y_pred == 1)\n",
    "false_negatives = (y_true == 1) & (y_pred == 0)\n",
    "true_positives = (y_true == 1) & (y_pred == 1)\n",
    "true_negatives = (y_true == 0) & (y_pred == 0)\n",
    "\n",
    "print(f\"False Positives: {false_positives.sum():,} ({false_positives.mean():.1%})\")\n",
    "print(f\"False Negatives: {false_negatives.sum():,} ({false_negatives.mean():.1%})\")\n",
    "print(f\"True Positives: {true_positives.sum():,} ({true_positives.mean():.1%})\")\n",
    "print(f\"True Negatives: {true_negatives.sum():,} ({true_negatives.mean():.1%})\")\n",
    "\n",
    "# Analyze characteristics of false positives vs true negatives\n",
    "print(\"\\n=== False Positive Analysis ===\")\n",
    "fp_characteristics = df[false_positives][['age', 'bmi', 'systolic_bp', 'glucose', 'cholesterol']].describe()\n",
    "tn_characteristics = df[true_negatives][['age', 'bmi', 'systolic_bp', 'glucose', 'cholesterol']].describe()\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'False_Positives': fp_characteristics.loc['mean'],\n",
    "    'True_Negatives': tn_characteristics.loc['mean']\n",
    "})\n",
    "comparison['Difference'] = comparison['False_Positives'] - comparison['True_Negatives']\n",
    "print(comparison.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze characteristics of false negatives vs true positives\n",
    "print(\"\\n=== False Negative Analysis ===\")\n",
    "fn_characteristics = df[false_negatives][['age', 'bmi', 'systolic_bp', 'glucose', 'cholesterol']].describe()\n",
    "tp_characteristics = df[true_positives][['age', 'bmi', 'systolic_bp', 'glucose', 'cholesterol']].describe()\n",
    "\n",
    "comparison_fn = pd.DataFrame({\n",
    "    'False_Negatives': fn_characteristics.loc['mean'],\n",
    "    'True_Positives': tp_characteristics.loc['mean']\n",
    "})\n",
    "comparison_fn['Difference'] = comparison_fn['False_Negatives'] - comparison_fn['True_Positives']\n",
    "print(comparison_fn.round(2))\n",
    "\n",
    "# Plot probability distributions for each prediction type\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(y_pred_proba[true_negatives], bins=50, alpha=0.7, label='True Negatives', color='blue')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.title('True Negatives - Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(y_pred_proba[false_positives], bins=50, alpha=0.7, label='False Positives', color='orange')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.title('False Positives - Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(y_pred_proba[true_positives], bins=50, alpha=0.7, label='True Positives', color='green')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.title('True Positives - Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(y_pred_proba[false_negatives], bins=50, alpha=0.7, label='False Negatives', color='red')\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.title('False Negatives - Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c87cd1",
   "metadata": {},
   "source": [
    "## 7. Model Calibration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_true, y_pred_proba, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Calibration plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, marker='o', linewidth=2, label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Histogram of predicted probabilities\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_pred_proba, bins=50, alpha=0.7, density=True)\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Predicted Probabilities')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate calibration metrics\n",
    "brier_score = np.mean((y_pred_proba - y_true) ** 2)\n",
    "print(f\"Brier Score: {brier_score:.4f} (lower is better)\")\n",
    "\n",
    "# Expected Calibration Error (ECE)\n",
    "bin_boundaries = np.linspace(0, 1, 11)\n",
    "bin_lowers = bin_boundaries[:-1]\n",
    "bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "ece = 0\n",
    "for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "    in_bin = (y_pred_proba > bin_lower) & (y_pred_proba <= bin_upper)\n",
    "    prop_in_bin = in_bin.mean()\n",
    "    \n",
    "    if prop_in_bin > 0:\n",
    "        accuracy_in_bin = y_true[in_bin].mean()\n",
    "        avg_confidence_in_bin = y_pred_proba[in_bin].mean()\n",
    "        ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "print(f\"Expected Calibration Error: {ece:.4f} (lower is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e607d82",
   "metadata": {},
   "source": [
    "## 8. ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da54d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR curves\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_true, y_pred_proba)\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_true, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {roc_auc_score(y_true, y_pred_proba):.3f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR Curve (AUC = {average_precision_score(y_true, y_pred_proba):.3f})')\n",
    "plt.axhline(y=y_true.mean(), color='gray', linestyle='--', label='Random')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Threshold vs F1 Score\n",
    "plt.subplot(1, 3, 3)\n",
    "thresholds = np.linspace(0.1, 0.9, 100)\n",
    "f1_scores = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_true, y_pred_thresh))\n",
    "\n",
    "plt.plot(thresholds, f1_scores, linewidth=2)\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label=f'Optimal Threshold = {optimal_threshold:.3f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Threshold vs F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca07f0",
   "metadata": {},
   "source": [
    "## 9. Improvement Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ca1b5",
   "metadata": {},
   "source": [
    "### Summary of Key Findings\n",
    "\n",
    "Based on the error analysis above, here are the key findings and recommendations for model improvement:\n",
    "\n",
    "#### 1. **Demographic Bias Issues**\n",
    "- Performance varies significantly across demographic groups\n",
    "- Some age groups or genders may have systematically different performance\n",
    "- **Recommendation**: Implement fairness constraints or post-processing calibration\n",
    "\n",
    "#### 2. **Temporal Stability**\n",
    "- Model performance may degrade over time due to data drift\n",
    "- Different years may have different performance characteristics\n",
    "- **Recommendation**: Implement monitoring for data drift and periodic retraining\n",
    "\n",
    "#### 3. **Feature Engineering Opportunities**\n",
    "- Current features may not capture all relevant clinical patterns\n",
    "- Interaction terms between important features could improve performance\n",
    "- **Recommendation**: Add feature interactions, polynomial terms, and domain-specific features\n",
    "\n",
    "#### 4. **Calibration Issues**\n",
    "- Model probabilities may not be well-calibrated\n",
    "- High/low Brier score or ECE indicates calibration problems\n",
    "- **Recommendation**: Apply probability calibration (Platt scaling or isotonic regression)\n",
    "\n",
    "#### 5. **Class Imbalance Handling**\n",
    "- Current imbalance handling may not be optimal\n",
    "- Consider alternative sampling strategies or cost-sensitive learning\n",
    "- **Recommendation**: Experiment with different SMOTE variants or focal loss\n",
    "\n",
    "#### 6. **Model Ensemble**\n",
    "- Single model may not capture all patterns\n",
    "- Different algorithms may have complementary strengths\n",
    "- **Recommendation**: Implement ensemble of diverse models (LightGBM + XGBoost + Neural Network)\n",
    "\n",
    "#### 7. **Uncertainty Quantification**\n",
    "- Current model doesn't provide uncertainty estimates\n",
    "- Medical applications benefit from knowing prediction confidence\n",
    "- **Recommendation**: Implement uncertainty quantification (e.g., conformal prediction)\n",
    "\n",
    "#### 8. **Label Quality**\n",
    "- Diagnosis year uncertainty affects model performance\n",
    "- Some misclassifications may be due to label noise\n",
    "- **Recommendation**: Implement confident learning to identify and handle label noise\n",
    "\n",
    "### Specific Next Steps:\n",
    "\n",
    "1. **Short-term (1-2 weeks)**:\n",
    "   - Apply probability calibration to improve reliability\n",
    "   - Implement basic fairness metrics monitoring\n",
    "   - Add more sophisticated feature interactions\n",
    "\n",
    "2. **Medium-term (1-2 months)**:\n",
    "   - Develop ensemble model with uncertainty quantification\n",
    "   - Implement data drift monitoring\n",
    "   - Create automated retraining pipeline\n",
    "\n",
    "3. **Long-term (3-6 months)**:\n",
    "   - Collect additional labeled data to address weak areas\n",
    "   - Implement advanced techniques like multi-task learning\n",
    "   - Develop specialized models for different subgroups\n",
    "\n",
    "### Success Metrics:\n",
    "- **Primary**: ROC-AUC > 0.85, PR-AUC > 0.60\n",
    "- **Fairness**: <5% AUC difference across demographic groups\n",
    "- **Calibration**: ECE < 0.05, Brier Score < 0.15\n",
    "- **Stability**: <2% performance degradation over 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "analysis_results = {\n",
    "    'overall_metrics': metrics,\n",
    "    'gender_analysis': gender_df.to_dict('records') if 'gender_df' in locals() else [],\n",
    "    'age_analysis': age_df.to_dict('records') if 'age_df' in locals() else [],\n",
    "    'smoking_analysis': smoking_df.to_dict('records') if 'smoking_df' in locals() else [],\n",
    "    'temporal_analysis': yearly_df.to_dict('records') if 'yearly_df' in locals() else [],\n",
    "    'calibration_metrics': {\n",
    "        'brier_score': float(brier_score),\n",
    "        'expected_calibration_error': float(ece)\n",
    "    },\n",
    "    'error_counts': {\n",
    "        'false_positives': int(false_positives.sum()),\n",
    "        'false_negatives': int(false_negatives.sum()),\n",
    "        'true_positives': int(true_positives.sum()),\n",
    "        'true_negatives': int(true_negatives.sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "import json\n",
    "with open('../models/error_analysis_results.json', 'w') as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(\"Error analysis completed and results saved to '../models/error_analysis_results.json'\")\n",
    "print(\"\\nKey recommendations:\")\n",
    "print(\"1. Implement probability calibration\")\n",
    "print(\"2. Address demographic bias through fairness constraints\")\n",
    "print(\"3. Add feature interactions and domain expertise\")\n",
    "print(\"4. Consider ensemble models for improved performance\")\n",
    "print(\"5. Implement monitoring for data drift and model degradation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
