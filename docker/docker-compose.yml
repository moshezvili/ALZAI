services:
  # Training Service
  clinical-ml-training:
    build:
      context: ..
      dockerfile: docker/Dockerfile.training
    container_name: clinical-ml-training
    volumes:
      - ../data:/app/data
      - ../models:/app/models
      - ../mlruns:/app/mlruns
    environment:
      - PYTHONPATH=/app
      - MLFLOW_TRACKING_URI=file:///app/mlruns
    command: >
      bash -c "
        echo 'Generating synthetic data...' &&
        python src/data_generation/generate_clinical_data.py --config config/training_config_docker_test.yaml --output_dir data/raw &&
        echo 'Training model...' &&
        python src/pipeline/training_pipeline.py --config config/training_config_docker_test.yaml --data data/raw/clinical_data.parquet --output models
      "
    networks:
      - clinical-ml-network

  # Serving Service  
  clinical-ml-serving:
    build:
      context: ..
      dockerfile: docker/Dockerfile.serving
    container_name: clinical-ml-serving
    ports:
      - "8000:8000"
    volumes:
      - ../models:/app/models:ro
      - ../config:/app/config:ro
    environment:
      - PYTHONPATH=/app
      - MODEL_DIR=/app/models
    depends_on:
      - clinical-ml-training
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - clinical-ml-network

  # MLflow Tracking Server (Optional)
  mlflow-server:
    image: python:3.9-slim
    container_name: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - ../mlruns:/app/mlruns
    working_dir: /app
    command: >
      bash -c "
        pip install mlflow &&
        mlflow server --backend-store-uri file:///app/mlruns --default-artifact-root file:///app/mlruns --host 0.0.0.0 --port 5000
      "
    networks:
      - clinical-ml-network

networks:
  clinical-ml-network:
    driver: bridge

volumes:
  clinical-ml-data:
  clinical-ml-models:
  clinical-ml-mlruns:
