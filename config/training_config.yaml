# Global
random_seed: 42

# Data Generation Configuration - Optimized for free servers
data_generation:
  num_patients: 1000            # Reduced from 5000 for free servers
  years_per_patient: 3          # Reduced from 5 for smaller dataset
  target_prevalence: 0.07
  output_format: "parquet"
  partition_by: ["year"]
  
  # Dask Configuration - Minimal for free servers
  use_dask: false               # Disabled for free servers
  batch_size: 500               # Smaller batches
  n_workers: 1                  # Single worker
  
  # Missing Value Simulation
  missing_values:
    enabled: true
    rates:
      cholesterol: 0.05      # 5% missing cholesterol (lab test unavailability)
      bmi: 0.10             # 10% missing BMI (failed measurements)
      glucose: 0.03         # 3% missing glucose (incomplete lab panels)
      blood_pressure: 0.02  # 2% missing blood pressure (equipment issues)
    
    # Alternative scenarios for different data quality settings
    scenarios:
      high_quality:
        cholesterol: 0.01
        bmi: 0.02
        glucose: 0.005
        blood_pressure: 0.01
      
      standard_practice:
        cholesterol: 0.05
        bmi: 0.10
        glucose: 0.03
        blood_pressure: 0.02
      
      resource_limited:
        cholesterol: 0.25
        bmi: 0.15
        glucose: 0.20
        blood_pressure: 0.08

# Feature Engineering Configuration
feature_engineering:
  rolling_window_years: 3
  min_periods: 1
  temporal_features: ["mean", "std", "trend", "min", "max"]
  categorical_encoding:
    method: "target_encoding"   # Make sure this is implemented within the pipeline (to avoid leakage between folds)
    handle_unknown: "ignore"
    cv_folds: 5  # K-Fold target encoding to prevent leakage
  
  # Scaling configuration (added after encoding)
  scaling:
    enabled: true
    method: "standard"  # "standard", "minmax", "robust"
  
  # Missing Value Handling (updated for realistic clinical data)
  missing_values:
    # Strategy for handling missing values in ML pipeline
    numeric_strategy: "median"
    categorical_strategy: "most_frequent"
    
    # Advanced missing value handling options
    advanced_imputation:
      enabled: false
      method: "iterative"  # or "knn"
      max_iter: 10
      random_state: 42
    
    # Missing value indicators (create binary flags for missingness)
    missing_indicators:
      enabled: true
      features: ["bmi", "cholesterol", "glucose", "systolic_bp", "diastolic_bp"]
      
    # Threshold for dropping features with too many missing values
    drop_threshold: 0.50  # Drop features with >50% missing

# Model Training Configuration
model:
  algorithm: "lightgbm"  # or "xgboost", "catboost"

  lightgbm:
    objective: "binary"
    metric: "auc"
    boosting_type: "gbdt"
    num_leaves: 15              # Reduced from 31 for free servers
    learning_rate: 0.1          # Increased for faster training with fewer trees
    feature_fraction: 0.8
    bagging_fraction: 0.8
    bagging_freq: 5
    min_child_samples: 20
    max_depth: 5                # Limited depth for free servers
    reg_alpha: 0.0
    reg_lambda: 0.0
    class_weight: null          # Disabled to avoid conflict with SMOTE
    random_state: 42
    n_estimators: 100           # Much fewer trees for free servers
    # early_stopping_rounds: 100  # Remove; the pipeline passes this through fit()

  xgboost:
    objective: "binary:logistic"
    eval_metric: "auc"
    max_depth: 4                # Reduced depth for free servers
    learning_rate: 0.1          # Increased for faster training
    n_estimators: 100           # Much fewer trees
    subsample: 0.8
    colsample_bytree: 0.8
    reg_alpha: 0.0
    reg_lambda: 1.0
    scale_pos_weight: 1         # Disabled because SMOTE is active
    random_state: 42
    # early_stopping_rounds: 100  # Remove; the pipeline passes this through fit()

# Class Imbalance Handling
imbalance:
  method: "smote"    # Enabled - handles class imbalance
  smote:
    sampling_strategy: 0.1     # Create 10% additional minority class samples
    k_neighbors: 5             # 5 nearest neighbors for synthetic sample creation
    random_state: 42

# Cross Validation
cross_validation:
  method: "stratified_temporal"   # Suitable for StratifiedTemporalSplitter
  n_splits: 5
  test_size: 0.2
  gap: 1
  year_col: "year"
  group_col: "patient_id"         # Patient-level separation between train/val
  prev_tolerance: 0.02
  group_disjoint: true

# Feature Selection (ACTIVE - implemented in FeatureSelector class)
feature_selection:
  method: "recursive_elimination"  # RFE with cross-validation
  max_features: 50                # Maximum features to select
  cv_folds: 3                    # Cross-validation folds for selection
  scoring: "roc_auc"             # Metric for ranking features

# Memory Management and Performance
memory:
  # Data loading and processing
  chunk_size: 10000
  max_memory_gb: 4

# Processing Configuration - Optimized for small/free servers
processing:
  # Distributed processing with Dask (conservative configuration for limited RAM)
  dask_config:
    n_workers: 1
    threads_per_worker: 2
    memory_limit: "512MB"      # Much safer - only 512MB per worker
    processes: false           # Use threads for better memory sharing
  
  # Data loading optimization
  sample_fraction: 0.2        # Increased to 20% since we're using less memory per worker
  large_dataset_threshold: 50000  # Much lower threshold for free servers
  
  # Parquet optimization
  parquet:
    engine: "pyarrow"
    compression: "snappy"
    row_group_size: 50000
    
  # Performance monitoring
  profiling:
    enabled: false
    output_dir: "./profiling"

# Threshold Selection
threshold:
  method: "f1_optimal"
  metric_weights:
    precision: 0.3
    recall: 0.7

# Hyperparameter Optimization (Optuna) - Minimal for free servers
hpo:
  enabled: false
  n_trials: 30
  timeout_sec: null
  opt_metric: "pr_auc"               # Options: "roc_auc", "pr_auc", "f1", "precision", "recall", "accuracy"
  algorithms: ["lightgbm", "xgboost", "catboost"]
  study_name: "clinical_hpo"

# Explainability - Minimal for free servers
explainability:
  shap:
    enabled: false             # Disabled for free servers - memory intensive
    nsample: 50                # Very small sample if enabled
    save_plots: false          # Disable to save memory
    save_table: true

# Experiment Tracking
mlflow:
  experiment_name: "clinical_binary_classification_v2"
  tracking_uri: "http://localhost:5000"
  log_artifacts: true
  log_model: true

# Model Evaluation
evaluation:
  metrics: ["roc_auc", "pr_auc", "f1_score", "precision", "recall", "accuracy"]
  
  # Slice analysis
  slice_analysis:
    categorical_features: ["gender", "age_group", "smoking_status"]
    min_samples_per_slice: 100
    
  # Data quality analysis
  data_quality:
    missing_value_analysis: true
    completeness_threshold: 0.70  # Flag if dataset completeness < 70%
    
    # Performance impact of missing values
    missing_impact_analysis:
      enabled: true
      compare_complete_cases: true
      missing_pattern_analysis: true
      
  # Robustness testing
  robustness:
    # Test model performance under different missing value scenarios
    missing_value_simulation:
      enabled: true
      test_scenarios: ["high_quality", "standard_practice", "resource_limited"]
